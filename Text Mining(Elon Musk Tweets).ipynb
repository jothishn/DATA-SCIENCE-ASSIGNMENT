{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4124e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import imread\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2e280",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385b07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "elon_files=pd.read_csv(\"C:\\\\Users\\\\JOTHISH N\\\\Desktop\\\\DS\\\\TEXT MINING\\\\Elon_musk.csv\",encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab4c9359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>1995</td>\n",
       "      <td>@flcnhvy True, it sounds so surreal, but the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>@PPathole Make sure to read ur terms &amp;amp; con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>@TeslaGong @PPathole Samwise Gamgee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>@PPathole Altho Dumb and Dumber is &lt;U+0001F525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>Progress update August 28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Text\n",
       "0              1                             @kunalb11 Im an alien\n",
       "1              2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...\n",
       "2              3                @joerogan @Spotify Great interview!\n",
       "3              4                    @gtera27 Doge is underestimated\n",
       "4              5  @teslacn Congratulations Tesla China for amazi...\n",
       "...          ...                                                ...\n",
       "1994        1995  @flcnhvy True, it sounds so surreal, but the n...\n",
       "1995        1996  @PPathole Make sure to read ur terms &amp; con...\n",
       "1996        1997                @TeslaGong @PPathole Samwise Gamgee\n",
       "1997        1998  @PPathole Altho Dumb and Dumber is <U+0001F525...\n",
       "1998        1999                          Progress update August 28\n",
       "\n",
       "[1999 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elon_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381dc3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping the reviews of spaces before and after the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713c0161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@kunalb11 I\\x92m an alien',\n",
       " '@ID_AA_Carmack Ray tracing on Cyberpunk with HDR is next-level. Have you tried it?',\n",
       " '@joerogan @Spotify Great interview!',\n",
       " '@gtera27 Doge is underestimated',\n",
       " '@teslacn Congratulations Tesla China for amazing execution last year. Now on to the next for even more!!',\n",
       " 'Happy New Year of the Ox! https://t.co/9WFKMYu2oj',\n",
       " 'Frodo was the underdoge,\\nAll thought he would fail,\\nHimself most of all. https://t.co/zGxJFDzzrM',\n",
       " '@OwenSparks_ @flcnhvy @anonyx10 Haha thanks :)',\n",
       " '@flcnhvy @anonyx10 Indeed! Tweets definitely do not represent real-world time allocation.',\n",
       " 'The most entertaining outcome is the most likely']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elon_musk = [x.strip() for x in elon_files.Text]\n",
    "elon_musk = [x for x in elon_musk if x]\n",
    "elon_musk[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce154c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1d98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735aeaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "sentences = tokenize.sent_tokenize(\" \".join(elon_musk))\n",
    "sentences[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90efd7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = pd.DataFrame(sentences, columns=['sentence'])\n",
    "sent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4270a6e9",
   "metadata": {},
   "source": [
    "Getting the negative words affinity values\n",
    "Putting affinity to be -1 for all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n = pd.read_csv(\"C:\\Users\\JOTHISH N\\Desktop\\DS\\TEXT MINING\\\\negative-words.txt\",sep=';', encoding='latin-1')\n",
    "afinn_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e85ade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "afinn_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb3134",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n=afinn_n.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49636a06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "afinn_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ae70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e9874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n=afinn_n.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8793ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n['value']=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20040b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15413b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e037bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n.columns=['words','value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea344667",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_p = pd.read_csv(\"C:\\Users\\JOTHISH N\\Desktop\\DS\\TEXT MINING\\\\positive-words.txt\",sep=';', encoding='latin-1')\n",
    "afinn_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the positive words affinity values\n",
    "# Putting affinity to be -1 for all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71cb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_p=afinn_p.iloc[:,0]\n",
    "afinn_p.dropna(inplace=True)\n",
    "afinn_p=afinn_p.reset_index()\n",
    "afinn_p['value']=1\n",
    "afinn_p.drop(['index'],axis=1,inplace=True)\n",
    "afinn_p.columns=['words','value']\n",
    "afinn_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d772e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b933b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb622a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinating the dataframes to get an affinity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d2c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "afinn=pd.concat([afinn_n,afinn_p],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbf6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9446fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_scores = afinn.set_index('words')['value'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44beae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ba355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to calculate sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb48ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "sentiment_lexicon = affinity_scores\n",
    "\n",
    "def calculate_sentiment(text: str = None):\n",
    "    sent_score = 0\n",
    "    if text:\n",
    "        sentence = nlp(text)\n",
    "        for word in sentence:\n",
    "            sent_score += sentiment_lexicon.get(word.lemma_, 0)\n",
    "    return sent_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d830492",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc686e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['sentiment_value'] = sent_df['sentence'].apply(calculate_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55edc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data with sentiment value less than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00027f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sent_df[sent_df.sentiment_value<-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f962c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data with sentiment value greater than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416af6f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sent_df[sent_df.sentiment_value>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finding the word count of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfaa860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sent_df['word_count'] = sent_df['sentence'].str.split().apply(len)\n",
    "sent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df.sort_values(by='sentiment_value').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['sentiment_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df[sent_df['sentiment_value']<=0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e81385",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting the sentiment value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a8b548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.lineplot(y=sent_df['sentiment_value'],x=sent_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting the scatterplot of sentiment value vs word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a2e79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sent_df.plot.scatter(x='word_count', y='sentiment_value', figsize=(8,8), \n",
    "                     title='Sentence sentiment value to sentence word count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539fd5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
